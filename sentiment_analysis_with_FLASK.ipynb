{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment-analysis-with-FLASK.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyZNZ1Tc4CkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0316a143-9bea-4c39-ed10-1e264637f919"
      },
      "source": [
        "!pip install numpy==1.16.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.7/dist-packages (1.16.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVzTvoFL4bW1"
      },
      "source": [
        "#Import Libraries\n",
        "import numpy\n",
        "from numpy import array\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import load_model\n",
        "import re\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I4_Ujly4lIs"
      },
      "source": [
        "np.random.seed(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR8zHyJE4yU2"
      },
      "source": [
        "%%capture\n",
        "\n",
        "# loading most frequent words\n",
        "top_words=5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPjs_MjVHpwX",
        "outputId": "f0f24506-c1f1-462e-877e-dfb302cd940c"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRcs7Kj35EA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e4cef4d-e3c0-4373-e14a-86ac92f04345"
      },
      "source": [
        "# word - id mapping\n",
        "word2id = imdb.get_word_index()\n",
        "\n",
        "# generating the id - word mapping\n",
        "id2word = {id:word for word, id in word2id.items()}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2KfNUK95mv3",
        "outputId": "b3833097-ad46-4af1-f84c-2c7498c447b6"
      },
      "source": [
        "# review 9\n",
        "print([id2word[i] for i in X_train[9]]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', 'as', 'on', 'there', 'plot', \"she's\", 'iii', 'film', 'that', 'for', 'find', 'that', 'saw', 'better', 'just', 'is', 'along', 'wrong', 'silly', 'awesome', 'or', 'play', 'this', 'you', 'doing', 'was', 'one', 'in', 'own', 'that', 'successful', 'are', 'make', 'and', 'old', 'plot', 'gets', 'unfortunately', 'of', 'on', 'was', 'although', 'except', 'value', 'and', 'that', 'with', 'her', 'do', 'they', 'gets', 'for', 'that', 'with', 'timing', 'really', 'way', 'that', 'is', 'played', 'character', 'i', 'i', 'what', 'poor', 'set', 'but', 'is', 'along', '100', 'studio', 'on', 'film', 'is', 'missing', 'br', 'received', 'fact', 'to', 'is', 'and', 'br', 'fabulous', 'and', 'them', 'powers', 'is', 'and', 'br', 'enjoys', 'and', 'good', 'women', 'show', 'to', 'one', 'good', 'played', 'i', 'i', 'was', 'plain', 'film', 'because', 'avoid', 'for', 'of', 'totally', 'it', 'time', 'do', 'period', 'it', 'couple', 'in', 'college', 'in', 'viewers', 'get', 'br', 'of', 'my', 'to', 'of', 'material', 'it', 'yet', 'br', 'out', 'more']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntqt4OiR6NPF",
        "outputId": "49a508ab-e312-4a22-b15d-17c4b5b4359b"
      },
      "source": [
        "print(f'max review length - {len(max((X_train + X_test), key=len))}')\n",
        "print(f'min review length - {len(min((X_train + X_test), key=len))}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max review length - 2697\n",
            "min review length - 70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_JZwX8cGuAY"
      },
      "source": [
        "max_review_length=500\n",
        "\n",
        "# padding reviews to limit length to 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECNs-9p6IpCf"
      },
      "source": [
        "# defining the neural network architecture\n",
        "\n",
        "embedding_vector_length = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziAIzw1FXVKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f94554-2dfb-4eb8-cc9e-a44416732e5a"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=10)\n",
        "mc = ModelCheckpoint('/content/drive/MyDrive/ML Projects/sentiment-analysis-using-FLASK/sentiment_analysis.h5', \n",
        "                     monitor='val_loss', save_best_only = True, verbose=1)\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=40, batch_size=64, callbacks=[es, mc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 500, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/40\n",
            "391/391 [==============================] - 33s 42ms/step - loss: 0.5756 - accuracy: 0.6681 - val_loss: 0.5006 - val_accuracy: 0.7588\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.50061, saving model to /content/drive/MyDrive/ML Projects/sentiment-analysis-using-FLASK/sentiment_analysis.h5\n",
            "Epoch 2/40\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.4252 - accuracy: 0.8144 - val_loss: 0.3697 - val_accuracy: 0.8407\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.50061 to 0.36970, saving model to /content/drive/MyDrive/ML Projects/sentiment-analysis-using-FLASK/sentiment_analysis.h5\n",
            "Epoch 3/40\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.7080 - accuracy: 0.6680 - val_loss: 0.6270 - val_accuracy: 0.6193\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.36970\n",
            "Epoch 4/40\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.5860 - accuracy: 0.6868 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.36970\n",
            "Epoch 5/40\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.3949 - accuracy: 0.8292 - val_loss: 0.3707 - val_accuracy: 0.8472\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.36970\n",
            "Epoch 6/40\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.2847 - accuracy: 0.8896 - val_loss: 0.3600 - val_accuracy: 0.8525\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.36970 to 0.36001, saving model to /content/drive/MyDrive/ML Projects/sentiment-analysis-using-FLASK/sentiment_analysis.h5\n",
            "Epoch 7/40\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.2451 - accuracy: 0.9059 - val_loss: 0.3382 - val_accuracy: 0.8634\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.36001 to 0.33820, saving model to /content/drive/MyDrive/ML Projects/sentiment-analysis-using-FLASK/sentiment_analysis.h5\n",
            "Epoch 8/40\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2131 - accuracy: 0.9224 - val_loss: 0.3339 - val_accuracy: 0.8697\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.33820 to 0.33386, saving model to /content/drive/MyDrive/ML Projects/sentiment-analysis-using-FLASK/sentiment_analysis.h5\n",
            "Epoch 9/40\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.2010 - accuracy: 0.9258 - val_loss: 0.3426 - val_accuracy: 0.8679\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.33386\n",
            "Epoch 10/40\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.1879 - accuracy: 0.9319 - val_loss: 0.3429 - val_accuracy: 0.8697\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.33386\n",
            "Epoch 11/40\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.1696 - accuracy: 0.9399 - val_loss: 0.3664 - val_accuracy: 0.8620\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.33386\n",
            "Epoch 12/40\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1847 - accuracy: 0.9316 - val_loss: 0.3628 - val_accuracy: 0.8702\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.33386\n",
            "Epoch 13/40\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1599 - accuracy: 0.9415 - val_loss: 0.3819 - val_accuracy: 0.8605\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.33386\n",
            "Epoch 14/40\n",
            "391/391 [==============================] - 15s 39ms/step - loss: 0.1409 - accuracy: 0.9503 - val_loss: 0.3966 - val_accuracy: 0.8562\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.33386\n",
            "Epoch 15/40\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.1517 - accuracy: 0.9440 - val_loss: 0.3792 - val_accuracy: 0.8583\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.33386\n",
            "Epoch 16/40\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.1394 - accuracy: 0.9511 - val_loss: 0.4301 - val_accuracy: 0.8655\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.33386\n",
            "Epoch 17/40\n",
            "391/391 [==============================] - 15s 40ms/step - loss: 0.1323 - accuracy: 0.9531 - val_loss: 0.4138 - val_accuracy: 0.8631\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.33386\n",
            "Epoch 18/40\n",
            "391/391 [==============================] - 16s 40ms/step - loss: 0.1199 - accuracy: 0.9572 - val_loss: 0.4177 - val_accuracy: 0.8556\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.33386\n",
            "Epoch 00018: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fec5824d4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}